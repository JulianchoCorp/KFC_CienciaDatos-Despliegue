{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0fae07-049f-4e04-8786-f43b90b09fe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5909c47d-f8d3-4653-b004-b058f3a71d82",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 5. Predicción de Resultados basados en el algoritmo\n",
    "______\n",
    "Una vez seleccionado el mejor model \"*LINEAR REGRESSION*\", se procedera a predecir el futuro de los datos. Para ello se deberá crear un DataFrame con los valores que se desean predecir.\n",
    "\n",
    "Para ello se carga un archivo de test con las ventas de los 3 meses posteriores al data origninal. Se procede a codificar el data y se pasara por el modelo seleccionado de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07db97f-3e17-4f52-825e-7d936d5ee810",
   "metadata": {},
   "source": [
    "## 5.1 Construcción del Data Frame para Predicción\n",
    "___\n",
    "Se generara un DataFrame con la simulacion de ventas del mes de Agosto- Diciembre de 2023, con un promedio de ventas diarias de 65. Así mismo, se utilizará como base los datos contenidos en el Data Frame de trabajo original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8ccce80-44c8-40b7-aab2-4470389fb9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIBRERIAS REQUERIDAS\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d981f05f-b5b7-4b9b-950a-953bf19a1229",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "raw_dir = cwd + \"/../Datos/raw/\"\n",
    "processed_dir = cwd + \"/../Datos/processed/\"\n",
    "final_dir = cwd + \"/../Datos/final/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "458ca68b-0379-41e4-b369-f3db7d90091d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unificado = pd.read_csv(processed_dir + 'datos_limpios_unidos.csv', parse_dates=['fecha_trans'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e9d1033-4b93-4504-b5b1-cbb801087cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 0 entries\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   fecha_trans  0 non-null      datetime64[ns]\n",
      " 1   cod_rest     0 non-null      object        \n",
      " 2   nom_rest     0 non-null      object        \n",
      " 3   canal        0 non-null      object        \n",
      " 4   medio        0 non-null      object        \n",
      "dtypes: datetime64[ns](1), object(4)\n",
      "memory usage: 124.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df_final = pd.DataFrame(columns=['fecha_trans','cod_rest','nom_rest','canal','medio'])    \n",
    "df_final['fecha_trans'] = pd.to_datetime(df_final['fecha_trans'])\n",
    "df_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59ebd7f6-4d8c-404f-b4e5-f8fad7eae1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DATAFRAME con Las Ciudades con mayor Cantidad de Ventas\n",
    "\n",
    "# Se crea una Lista con las 50 ciudades(incluyendo Departamento) con mayor cantidad de ventas.\n",
    "df_list_rest = df_unificado.groupby(['nom_rest','cod_rest'], as_index=False)[['valor_trans']].count().sort_values(by='valor_trans', ascending=False)\n",
    "\n",
    "# Obtenemos las Primeras cincuenta filas que corresponden a las ciudades con más cantidad de ventas.\n",
    "df_list_rest_df = df_list_rest.iloc[:,[0,1]]\n",
    "\n",
    "# Pasamos las columnas del DataFrame a una Matriz por el metodo to_numpy.\n",
    "lista_rest = df_list_rest_df.to_numpy()\n",
    "\n",
    "# Lista de los dispositivos\n",
    "lista_canal = df_unificado['canal'].unique().tolist()\n",
    "\n",
    "rappi = ['rappi']\n",
    "didi = ['didi']\n",
    "ifood = ['Marketifood','LOGISTIC']\n",
    "app = ['Ios','Android']\n",
    "callcenter = ['callcenter']\n",
    "web = ['Web']\n",
    "tictuk = ['tictuk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4934f8e-c1b5-4b78-8048-8d12495d5b16",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Creamos Las Fechas del tiempo estimado entre agosto - diciembre 2023 a un promedio de 65 ventas dia.\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m inicio \u001b[38;5;241m=\u001b[39m \u001b[43mdatetime\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2023\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m fin    \u001b[38;5;241m=\u001b[39m datetime(\u001b[38;5;241m2023\u001b[39m,\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m30\u001b[39m)\n\u001b[0;32m      4\u001b[0m fecha_tot \u001b[38;5;241m=\u001b[39m[]\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "# Creamos Las Fechas del tiempo estimado entre agosto - diciembre 2023 a un promedio de 65 ventas dia.\n",
    "inicio = datetime(2023,5,1)\n",
    "fin    = datetime(2023,8,30)\n",
    "fecha_tot =[]\n",
    "for i in range (65):\n",
    "    fecha_dia =[(inicio + timedelta(days=d)).strftime(\"%Y-%m-%d\")\n",
    "                    for d in range((fin - inicio).days + 1)]\n",
    "    fecha_tot.extend(fecha_dia)\n",
    "#print(len(fecha_tot))\n",
    "\n",
    "# Nos Permite Validar La cantidad de registros que se crearan para el DataFrame (5 Meses * 30 dias* 65 ventas dia)\n",
    "TotFilas = len(fecha_tot)\n",
    "\n",
    "# Generamos las ciudades aleatorias para nuestros registros.\n",
    "rest_aleat1 = []\n",
    "rest_aleat2 = []\n",
    "for fila in range(TotFilas):\n",
    "    aleat_rest = random.choice(lista_rest) # Permite obtener un valor aleatorio de una lista.\n",
    "    #print (aleat_rest)\n",
    "    rest_aleat1.append(aleat_rest[0])\n",
    "    rest_aleat2.append(aleat_rest[1])\n",
    "\n",
    "\n",
    "# Generamos los canal aleatorios para nuestros registros\n",
    "canal_aleat = []\n",
    "for fila3 in range(TotFilas):\n",
    "    aleat_tipo = random.choice(lista_canal)\n",
    "    canal_aleat.append(aleat_tipo)\n",
    "\n",
    "\n",
    "# Generamos las medios aleatorias para nuestros registros\n",
    "medio_aleat = []\n",
    "for fila2 in range(TotFilas):\n",
    "    if canal_aleat[fila2] == 'rappi':\n",
    "        aleat_medio = random.choice(rappi)\n",
    "    elif canal_aleat[fila2] == 'didi':\n",
    "        aleat_medio = random.choice(didi)\n",
    "    elif canal_aleat[fila2] == 'ifood':\n",
    "        aleat_medio = random.choice(ifood)\n",
    "    elif canal_aleat[fila2] == 'app':\n",
    "        aleat_medio = random.choice(app)\n",
    "    elif canal_aleat[fila2] == 'callcenter':\n",
    "        aleat_medio = random.choice(callcenter)\n",
    "    elif canal_aleat[fila2] == 'web':\n",
    "        aleat_medio = random.choice(web)\n",
    "    elif canal_aleat[fila2] == 'tictuk':\n",
    "        aleat_medio = random.choice(tictuk)\n",
    "    else:    \n",
    "        aleat_medio = 'Otra'\n",
    "        \n",
    "    medio_aleat.append(aleat_medio)\n",
    "    \n",
    "# Generamos los valores aleatorios para nuestros registros\n",
    "#val_aleat = []\n",
    "#for fila3 in range(TotFilas):\n",
    "#    aleat_valor = random.choice(lista_valor)\n",
    "#    val_aleat.append(aleat_valor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ed1276fe-191a-4888-a16b-a860c207df8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Igualamos las Listas y Matrices a cada columna de nuestro DataFrame Final.\n",
    "df_final['fecha_trans'] =  fecha_tot # Fecha de Venta\n",
    "df_final['nom_rest'] =  rest_aleat1  # Ciudad\n",
    "df_final['cod_rest'] =  rest_aleat2 # Departamento\n",
    "df_final['canal'] =  canal_aleat # Tipo de Dispositivo\n",
    "df_final['medio'] =  medio_aleat\n",
    "#df_final['VALOR_TOTAL'] =  val_aleat\n",
    "\n",
    "# Convertimos la varible FECHA_VENTA de Objeto a Fecha.\n",
    "df_final['fecha_trans'] = pd.to_datetime(df_final['fecha_trans'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4048af59-b8fc-427a-8d22-396b949e079a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenamos el orden de columnas para el DataFrame.\n",
    "df_final = df_final[['fecha_trans','nom_rest','cod_rest','canal','medio']]\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d28259-0b38-4030-82ca-1f84e59e25c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_final.to_csv(final_dir + 'final_test.csv',index=False)\n",
    "# Se crea el DataFrame para el modelo.\n",
    "df_final_test = df_final.copy()\n",
    "#df_final_test['FECHA_VENTA'] = df_final['FECHA_VENTA'].astype('object')\n",
    "df_final_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53569332-6da3-4c09-8d07-225e3cdddf52",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5.2 Codificación del Data Frame de Test.\n",
    "___\n",
    "Para llevar a cabo el proceso de entrenamiento se requiere codificar el DataFrame. Para ello, se realizará el mismo proceso del DF original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a40e82f-7739-41a1-910d-1a0ccdb6e63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "# Función que permite crear las columnas de dia,mes,año\n",
    "def funcion_fecha(x):\n",
    "    \n",
    "    año = x[0:4]\n",
    "    mes = x[5:7]\n",
    "    dia = x[8:10]\n",
    "    return datetime.datetime(int(año), int(mes), int(dia))\n",
    "\n",
    "df_final_test['fecha_trans'] = df_final_test['fecha_trans'].apply(lambda x : funcion_fecha(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0249e27-40be-4ed2-bb80-383dc5b917a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea cada columna correspondiente a la fecha del registro\n",
    "df_final_test['mes'] = df_final_test['fecha_trans'].apply(lambda x: x.month)\n",
    "df_final_test['anio'] = df_final_test['fecha_trans'].apply(lambda x: x.year)\n",
    "df_final_test['dia'] = df_final_test['fecha_trans'].apply(lambda x: x.day)\n",
    "df_final_test['dia_semana'] = df_final_test['fecha_trans'].apply(lambda x: x.weekday())\n",
    "df_final_test = df_final_test.drop(columns ='fecha_trans')\n",
    "df_final_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ab7af0-0132-44cd-8a4f-dc50c76202cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se realiza una copia del Dataframe Actual y se traslada al\n",
    "# Data Frame df_dummy el cual almacenara los cambios de codificación.\n",
    "df_dummy_test = df_final_test.copy()\n",
    "#df_dummy_test['CIUDAD'] = df_dummy_test['CIUDAD'].str.strip()\n",
    "df_dummy_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d99ad1-8285-41bd-9144-94291b8d6833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos una función que se encargará de codificar las columnas\n",
    "def dummies_test(df_dummy_test):\n",
    "    \n",
    "  df_dummy_test = pd.get_dummies(df_dummy_test, columns=['cod_rest'])\n",
    "  df_dummy_test = pd.get_dummies(df_dummy_test, columns=['canal'])\n",
    "  df_dummy_test = pd.get_dummies(df_dummy_test, columns=['medio'])\n",
    "  df_dummy_test = pd.get_dummies(df_dummy_test, columns=['nom_rest'])\n",
    "      \n",
    "  return df_dummy_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ff83e5-c7dc-480f-9d96-2321efe44e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se procede a aplicar la función al Dataframe para aplicar los cambios de codificación.\n",
    "df_dummy_test = dummies_test(df_dummy_test)\n",
    "\n",
    "df_dummy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0147a270-a823-42d0-b69b-1fcdeb331169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea el DataFrame para el modelo.\n",
    "df_modelo_test = df_dummy_test.copy()\n",
    "\n",
    "df_modelo_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e31db65-2727-4fff-808a-169528f9a60c",
   "metadata": {},
   "source": [
    "## 5.3 Pasando el Data Frame por el Modelo De Entrenamiento.\n",
    "___\n",
    "Una vez se ha generado el DataFrame, se pasa el mismo por la variable de Predicción resultante del entrenamiento. Esto con el objetivo que nos genere las ventas futuras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7d263d-b29b-44b4-b21d-7886077026ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se pasa el DataFrame por el Modelo de Entrenamiento.\n",
    "y_pred_LR_2=LinReg.predict(df_modelo_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2a8907-d394-4de4-a71d-4b65f42ef8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea el DF Final partiendo de las columnas originales. Luego se le anexará la columna de predicción\n",
    "df_futuro = df_final.copy()\n",
    "df_futuro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c9a7f5-dfee-4507-b616-1de57551d0b2",
   "metadata": {},
   "source": [
    "## 5.4 Se crea el Data Frame de Valores Futuros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8003d88a-7add-4a4a-b692-4ec030d09052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea la Columna VALOR_TOTAL asignandole la variable de PREDICCION.\n",
    "df_futuro['valor_trans'] = y_pred_LR_2\n",
    "df_futuro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0b9309-4eef-4344-9d56-6c708cea0f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se redondea el valor de la columna VALOR_TOTAL a 1 decimal.\n",
    "df_futuro = df_futuro.round(0) \n",
    "df_futuro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777de33d-d865-49fd-a348-1a84f8ee9462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenamos las filas del DataFrame Organizadas por la Fecha de Venta.\n",
    "df_futuro = df_futuro.sort_values('fecha_trans',ascending=True)\n",
    "df_futuro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844803f5-c03d-4cb6-b1a5-25519cda6aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se genera el archivo CSV partiendo del DF.\n",
    "df_futuro.to_csv(final_dir + 'final_Datos_futuro.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
